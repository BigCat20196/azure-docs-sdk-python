### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.EdgeNGramTokenizer
name: EdgeNGramTokenizer
fullName: azure.search.documents.indexes.models.EdgeNGramTokenizer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.v2020_06_preview.models._models_py3.LexicalTokenizer
summary: 'Tokenizes the input from an edge into n-grams of the given size(s). This
  tokenizer is implemented using Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'EdgeNGramTokenizer(*, name: str, min_gram: Optional[int] = 1, max_gram:
    Optional[int] = 2, token_chars: Optional[List[str]] = None, **kwargs)'
  parameters:
  - name: odata_type
    description: 'Required. Identifies the concrete type of the tokenizer.Constant
      filled by

      server.'
    types:
    - '[str](https://docs.python.org/3.6/library/stdtypes.html#str)'
  - name: name
    description: 'Required. The name of the tokenizer. It must only contain letters,
      digits, spaces,

      dashes or underscores, can only start and end with alphanumeric characters,
      and is limited to

      128 characters.'
    types:
    - '[str](https://docs.python.org/3.6/library/stdtypes.html#str)'
  - name: min_gram
    description: 'The minimum n-gram length. Default is 1. Maximum is 300. Must be
      less than the

      value of maxGram.'
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  - name: max_gram
    description: The maximum n-gram length. Default is 2. Maximum is 300.
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  - name: token_chars
    description: Character classes to keep in the tokens.
    types:
    - '[list](https://docs.python.org/3.6/library/stdtypes.html#list)[[str](https://docs.python.org/3.6/library/stdtypes.html#str'
