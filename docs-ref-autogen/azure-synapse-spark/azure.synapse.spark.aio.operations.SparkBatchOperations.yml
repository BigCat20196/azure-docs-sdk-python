### YamlMime:PythonClass
uid: azure.synapse.spark.aio.operations.SparkBatchOperations
name: SparkBatchOperations
fullName: azure.synapse.spark.aio.operations.SparkBatchOperations
module: azure.synapse.spark.aio.operations
inheritances:
- builtins.object
summary: 'SparkBatchOperations async operations.


  You should not instantiate this class directly. Instead, you should create a Client
  instance that

  instantiates it for you and attaches it as an attribute.'
constructor:
  syntax: SparkBatchOperations(client, config, serializer, deserializer) -> None
  parameters:
  - name: client
    description: Client for service requests.
  - name: config
    description: Configuration of service client.
  - name: serializer
    description: An object model serializer.
  - name: deserializer
    description: An object model deserializer.
variables:
- description: Alias to model classes used in this operation group.
  name: "models \u2013 Alias to model classes used in this operation group"
methods:
- uid: azure.synapse.spark.aio.operations.SparkBatchOperations.cancel_spark_batch_job
  name: cancel_spark_batch_job
  summary: Cancels a running spark batch job.
  signature: 'cancel_spark_batch_job(batch_id: int, **kwargs) -> None'
  parameters:
  - name: batch_id
    description: Identifier for the batch job.
    isRequired: true
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  return:
    description: None, or the result of cls(response)
    types:
    - '[None](https://docs.python.org/3.6/library/constants.html#None)'
- uid: azure.synapse.spark.aio.operations.SparkBatchOperations.create_spark_batch_job
  name: create_spark_batch_job
  summary: Create new spark batch job.
  signature: 'create_spark_batch_job(spark_batch_job_options: azure.synapse.spark.models._models_py3.SparkBatchJobOptions,
    detailed: Optional[bool] = None, **kwargs) -> ''_models.SparkBatchJob'''
  parameters:
  - name: spark_batch_job_options
    description: Livy compatible batch job request payload.
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkBatchJobOptions>
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - '[bool](https://docs.python.org/3.6/library/functions.html#bool)'
  return:
    description: SparkBatchJob, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkBatchJob>
- uid: azure.synapse.spark.aio.operations.SparkBatchOperations.get_spark_batch_job
  name: get_spark_batch_job
  summary: Gets a single spark batch job.
  signature: 'get_spark_batch_job(batch_id: int, detailed: Optional[bool] = None,
    **kwargs) -> ''_models.SparkBatchJob'''
  parameters:
  - name: batch_id
    description: Identifier for the batch job.
    isRequired: true
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - '[bool](https://docs.python.org/3.6/library/functions.html#bool)'
  return:
    description: SparkBatchJob, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkBatchJob>
- uid: azure.synapse.spark.aio.operations.SparkBatchOperations.get_spark_batch_jobs
  name: get_spark_batch_jobs
  summary: List all spark batch jobs which are running under a particular spark pool.
  signature: 'get_spark_batch_jobs(from_parameter: Optional[int] = None, size: Optional[int]
    = None, detailed: Optional[bool] = None, **kwargs) -> ''_models.SparkBatchJobCollection'''
  parameters:
  - name: from_parameter
    description: Optional param specifying which index the list should begin from.
    defaultValue: None
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  - name: size
    description: 'Optional param specifying the size of the returned list.

      By default it is 20 and that is the maximum.'
    defaultValue: None
    types:
    - '[int](https://docs.python.org/3.6/library/functions.html#int)'
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - '[bool](https://docs.python.org/3.6/library/functions.html#bool)'
  return:
    description: SparkBatchJobCollection, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkBatchJobCollection>
attributes:
- uid: azure.synapse.spark.aio.operations.SparkBatchOperations.models
  name: models
  signature: models = <module 'azure.synapse.spark.models' from 'c:\\hostedtoolcache\\windows\\python\\3.6.8\\x64\\lib\\site-packages\\azure\\synapse\\spark\\models\\__init__.py'>
