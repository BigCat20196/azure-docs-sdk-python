### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_session
  - azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_statement
  - azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_session
  - azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_statement
  - azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_session
  - azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_sessions
  - azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statement
  - azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statements
  - azure.synapse.spark.aio.operations.SparkSessionOperations.reset_spark_session_timeout
  - azure.synapse.spark.aio.operations.SparkSessionOperations.models
  class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: SparkSessionOperations
  summary: 'SparkSessionOperations async operations.


    You should not instantiate this class directly. Instead, you should create a Client
    instance that

    instantiates it for you and attaches it as an attribute.'
  syntax:
    content: SparkSessionOperations(client, config, serializer, deserializer) -> None
    parameters:
    - description: Client for service requests.
      id: client
    - description: Configuration of service client.
      id: config
    - description: An object model serializer.
      id: serializer
    - description: An object model deserializer.
      id: deserializer
    variables:
    - description: Alias to model classes used in this operation group.
      id: models
  type: class
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_session
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'cancel_spark_session(session_id: int, **kwargs) -> None'
  namewithoutparameters: cancel_spark_session
  summary: Cancels a running spark session.
  syntax:
    content: 'cancel_spark_session(session_id: int, **kwargs) -> None'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: None, or the result of cls(response)
      type:
      - None
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_session
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_statement
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'cancel_spark_statement(session_id: int, statement_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatementCancellationResult'
  namewithoutparameters: cancel_spark_statement
  summary: Kill a statement within a session.
  syntax:
    content: 'cancel_spark_statement(session_id: int, statement_id: int, **kwargs)
      -> azure.synapse.spark.models._models_py3.SparkStatementCancellationResult'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: Identifier for the statement.
      id: statement_id
      isRequired: true
      type:
      - int
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkStatementCancellationResult, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkStatementCancellationResult
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_statement
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_session
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'create_spark_session(spark_session_options: azure.synapse.spark.models._models_py3.SparkSessionOptions,
    detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
  namewithoutparameters: create_spark_session
  summary: Create new spark session.
  syntax:
    content: 'create_spark_session(spark_session_options: azure.synapse.spark.models._models_py3.SparkSessionOptions,
      detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
    parameters:
    - description: Livy compatible batch job request payload.
      id: spark_session_options
      isRequired: true
      type:
      - azure.synapse.spark.models.SparkSessionOptions
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      isRequired: true
      type:
      - bool
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkSession, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkSession
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_session
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_statement
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'create_spark_statement(session_id: int, spark_statement_options: azure.synapse.spark.models._models_py3.SparkStatementOptions,
    **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatement'
  namewithoutparameters: create_spark_statement
  summary: Create statement within a spark session.
  syntax:
    content: 'create_spark_statement(session_id: int, spark_statement_options: azure.synapse.spark.models._models_py3.SparkStatementOptions,
      **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatement'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: Livy compatible batch job request payload.
      id: spark_statement_options
      isRequired: true
      type:
      - azure.synapse.spark.models.SparkStatementOptions
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkStatement, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkStatement
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_statement
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_session
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'get_spark_session(session_id: int, detailed: typing.Union[bool, NoneType]
    = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
  namewithoutparameters: get_spark_session
  summary: Gets a single spark session.
  syntax:
    content: 'get_spark_session(session_id: int, detailed: typing.Union[bool, NoneType]
      = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      isRequired: true
      type:
      - bool
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkSession, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkSession
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_session
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_sessions
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'get_spark_sessions(from_parameter: typing.Union[int, NoneType] = None, size:
    typing.Union[int, NoneType] = None, detailed: typing.Union[bool, NoneType] = None,
    **kwargs) -> azure.synapse.spark.models._models_py3.SparkSessionCollection'
  namewithoutparameters: get_spark_sessions
  summary: List all spark sessions which are running under a particular spark pool.
  syntax:
    content: 'get_spark_sessions(from_parameter: typing.Union[int, NoneType] = None,
      size: typing.Union[int, NoneType] = None, detailed: typing.Union[bool, NoneType]
      = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSessionCollection'
    parameters:
    - description: Optional param specifying which index the list should begin from.
      id: from_parameter
      isRequired: true
      type:
      - int
    - description: 'Optional param specifying the size of the returned list.

        By default it is 20 and that is the maximum.'
      id: size
      isRequired: true
      type:
      - int
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      isRequired: true
      type:
      - bool
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkSessionCollection, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkSessionCollection
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_sessions
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statement
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'get_spark_statement(session_id: int, statement_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatement'
  namewithoutparameters: get_spark_statement
  summary: Gets a single statement within a spark session.
  syntax:
    content: 'get_spark_statement(session_id: int, statement_id: int, **kwargs) ->
      azure.synapse.spark.models._models_py3.SparkStatement'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: Identifier for the statement.
      id: statement_id
      isRequired: true
      type:
      - int
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkStatement, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkStatement
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statement
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statements
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'get_spark_statements(session_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatementCollection'
  namewithoutparameters: get_spark_statements
  summary: Gets a list of statements within a spark session.
  syntax:
    content: 'get_spark_statements(session_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatementCollection'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: SparkStatementCollection, or the result of cls(response)
      type:
      - azure.synapse.spark.models.SparkStatementCollection
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statements
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.reset_spark_session_timeout
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: 'reset_spark_session_timeout(session_id: int, **kwargs) -> None'
  namewithoutparameters: reset_spark_session_timeout
  summary: Sends a keep alive call to the current session to reset the session timeout.
  syntax:
    content: 'reset_spark_session_timeout(session_id: int, **kwargs) -> None'
    parameters:
    - description: Identifier for the session.
      id: session_id
      isRequired: true
      type:
      - int
    - description: A custom type or function that will be passed the direct response
      id: cls
      isRequired: true
      type:
      - callable
    return:
      description: None, or the result of cls(response)
      type:
      - None
  type: method
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.reset_spark_session_timeout
- class: azure.synapse.spark.aio.operations.SparkSessionOperations
  fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.models
  langs:
  - python
  module: azure.synapse.spark.aio.operations
  name: models
  syntax:
    content: models = <module 'azure.synapse.spark.models' from 'c:\\hostedtoolcache\\windows\\python\\3.6.8\\x64\\lib\\site-packages\\azure\\synapse\\spark\\models\\__init__.py'>
  type: attribute
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.models
references:
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_session
  isExternal: false
  name: 'cancel_spark_session(session_id: int, **kwargs) -> None'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_session
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_statement
  isExternal: false
  name: 'cancel_spark_statement(session_id: int, statement_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatementCancellationResult'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.cancel_spark_statement
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_session
  isExternal: false
  name: 'create_spark_session(spark_session_options: azure.synapse.spark.models._models_py3.SparkSessionOptions,
    detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_session
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_statement
  isExternal: false
  name: 'create_spark_statement(session_id: int, spark_statement_options: azure.synapse.spark.models._models_py3.SparkStatementOptions,
    **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatement'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.create_spark_statement
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_session
  isExternal: false
  name: 'get_spark_session(session_id: int, detailed: typing.Union[bool, NoneType]
    = None, **kwargs) -> azure.synapse.spark.models._models_py3.SparkSession'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_session
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_sessions
  isExternal: false
  name: 'get_spark_sessions(from_parameter: typing.Union[int, NoneType] = None, size:
    typing.Union[int, NoneType] = None, detailed: typing.Union[bool, NoneType] = None,
    **kwargs) -> azure.synapse.spark.models._models_py3.SparkSessionCollection'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_sessions
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statement
  isExternal: false
  name: 'get_spark_statement(session_id: int, statement_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatement'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statement
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statements
  isExternal: false
  name: 'get_spark_statements(session_id: int, **kwargs) -> azure.synapse.spark.models._models_py3.SparkStatementCollection'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.get_spark_statements
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.reset_spark_session_timeout
  isExternal: false
  name: 'reset_spark_session_timeout(session_id: int, **kwargs) -> None'
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.reset_spark_session_timeout
- fullName: azure.synapse.spark.aio.operations.SparkSessionOperations.models
  isExternal: false
  name: models
  parent: azure.synapse.spark.aio.operations.SparkSessionOperations
  uid: azure.synapse.spark.aio.operations.SparkSessionOperations.models
