### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: azure.synapse.artifacts.models.AzureDatabricksLinkedService
  fullName: azure.synapse.artifacts.models.AzureDatabricksLinkedService
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: msrest.serialization.Model
    type: azure.synapse.artifacts.models._models_py3.LinkedService
  langs:
  - python
  module: azure.synapse.artifacts.models
  name: AzureDatabricksLinkedService
  summary: 'Azure Databricks linked service.


    All required parameters must be populated in order to send to Azure.'
  syntax:
    content: 'AzureDatabricksLinkedService(*, domain: object, access_token: azure.synapse.artifacts.models._models_py3.SecretBase,
      additional_properties: typing.Union[typing.Dict[str, object], NoneType] = None,
      connect_via: typing.Union[_ForwardRef(''IntegrationRuntimeReference''), NoneType]
      = None, description: typing.Union[str, NoneType] = None, parameters: typing.Union[typing.Dict[str,
      _ForwardRef(''ParameterSpecification'')], NoneType] = None, annotations: typing.Union[typing.List[object],
      NoneType] = None, existing_cluster_id: object = None, instance_pool_id: object
      = None, new_cluster_version: object = None, new_cluster_num_of_worker: object
      = None, new_cluster_node_type: object = None, new_cluster_spark_conf: typing.Union[typing.Dict[str,
      object], NoneType] = None, new_cluster_spark_env_vars: typing.Union[typing.Dict[str,
      object], NoneType] = None, new_cluster_custom_tags: typing.Union[typing.Dict[str,
      object], NoneType] = None, new_cluster_driver_node_type: object = None, new_cluster_init_scripts:
      object = None, new_cluster_enable_elastic_disk: object = None, encrypted_credential:
      object = None, **kwargs)'
    parameters:
    - description: 'Unmatched properties from the message are deserialized to this

        collection.'
      id: additional_properties
      type:
      - dict[str, object]
    - description: Required. Type of linked service.Constant filled by server.
      id: type
      type:
      - str
    - description: The integration runtime reference.
      id: connect_via
      type:
      - azure.synapse.artifacts.models.IntegrationRuntimeReference
    - description: Linked service description.
      id: description
      type:
      - str
    - description: Parameters for linked service.
      id: parameters
      type:
      - dict[str, azure.synapse.artifacts.models.ParameterSpecification]
    - description: List of tags that can be used for describing the linked service.
      id: annotations
      type:
      - list[object]
    - description: 'Required. `<REGION>`.azuredatabricks.net, domain name of your
        Databricks

        deployment. Type: string (or Expression with resultType string).'
      id: domain
      type:
      - object
    - description: 'Required. Access token for databricks REST API. Refer to

        [https://docs.azuredatabricks.net/api/latest/authentication.html](https://docs.azuredatabricks.net/api/latest/authentication.html).
        Type: string (or Expression

        with resultType string).'
      id: access_token
      type:
      - azure.synapse.artifacts.models.SecretBase
    - description: 'The id of an existing interactive cluster that will be used for
        all

        runs of this activity. Type: string (or Expression with resultType string).'
      id: existing_cluster_id
      type:
      - object
    - description: 'The id of an existing instance pool that will be used for all
        runs of

        this activity. Type: string (or Expression with resultType string).'
      id: instance_pool_id
      type:
      - object
    - description: 'If not using an existing interactive cluster, this specifies the

        Spark version of a new job cluster or instance pool nodes created for each
        run of this

        activity. Required if instancePoolId is specified. Type: string (or Expression
        with resultType

        string).'
      id: new_cluster_version
      type:
      - object
    - description: 'If not using an existing interactive cluster, this specifies

        the number of worker nodes to use for the new job cluster or instance pool.
        For new job

        clusters, this a string-formatted Int32, like ''1'' means numOfWorker is 1
        or ''1:10'' means auto-

        scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted
        Int32, and can

        only specify a fixed number of worker nodes, such as ''2''. Required if newClusterVersion
        is

        specified. Type: string (or Expression with resultType string).'
      id: new_cluster_num_of_worker
      type:
      - object
    - description: 'The node type of the new job cluster. This property is required

        if newClusterVersion is specified and instancePoolId is not specified. If
        instancePoolId is

        specified, this property is ignored. Type: string (or Expression with resultType
        string).'
      id: new_cluster_node_type
      type:
      - object
    - description: 'A set of optional, user-specified Spark configuration key-value

        pairs.'
      id: new_cluster_spark_conf
      type:
      - dict[str, object]
    - description: 'A set of optional, user-specified Spark environment

        variables key-value pairs.'
      id: new_cluster_spark_env_vars
      type:
      - dict[str, object]
    - description: 'Additional tags for cluster resources. This property is ignored

        in instance pool configurations.'
      id: new_cluster_custom_tags
      type:
      - dict[str, object]
    - description: 'The driver node type for the new job cluster. This

        property is ignored in instance pool configurations. Type: string (or Expression
        with

        resultType string).'
      id: new_cluster_driver_node_type
      type:
      - object
    - description: 'User-defined initialization scripts for the new cluster. Type:

        array of strings (or Expression with resultType array of strings).'
      id: new_cluster_init_scripts
      type:
      - object
    - description: 'Enable the elastic disk on the new cluster. This

        property is now ignored, and takes the default elastic disk behavior in Databricks
        (elastic

        disks are always enabled). Type: boolean (or Expression with resultType boolean).'
      id: new_cluster_enable_elastic_disk
      type:
      - object
    - description: 'The encrypted credential used for authentication. Credentials
        are

        encrypted using the integration runtime credential manager. Type: string (or
        Expression with

        resultType string).'
      id: encrypted_credential
      type:
      - object
  type: class
  uid: azure.synapse.artifacts.models.AzureDatabricksLinkedService
references:
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str, azure.synapse.artifacts.models.ParameterSpecification]
  name: dict[str, ParameterSpecification]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: azure.synapse.artifacts.models.ParameterSpecification
    name: ParameterSpecification
    uid: azure.synapse.artifacts.models.ParameterSpecification
  - fullName: ']'
    name: ']'
  uid: dict[str, azure.synapse.artifacts.models.ParameterSpecification]
- fullName: list[object]
  name: list[object]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: list[object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
